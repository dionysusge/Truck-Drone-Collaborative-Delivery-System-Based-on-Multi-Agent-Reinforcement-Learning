#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
ä½œè€…: Dionysus
è”ç³»æ–¹å¼: wechat:gzw1546484791

åŠŸèƒ½:
- åŠ è½½è®­ç»ƒå¥½çš„MAPPOæ¨¡å‹
- è¿è¡Œå¤šä¸ªæµ‹è¯•å›åˆ
- æ˜¾ç¤ºæµ‹è¯•ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
"""

import os
import sys
import torch
import numpy as np
from typing import Dict, List, Any
import argparse

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from truck_routing import TruckSchedulingEnv, MAPPO
import config


def infer_env_config_from_model(checkpoint: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä»æ¨¡å‹checkpointä¸­æ¨æ–­è®­ç»ƒæ—¶çš„ç¯å¢ƒé…ç½®
    
    Args:
        checkpoint: æ¨¡å‹checkpointå­—å…¸
        
    Returns:
        ç¯å¢ƒé…ç½®å­—å…¸ï¼ŒåŒ…å« num_lockers, state_dim, num_trucks ç­‰ä¿¡æ¯
    """
    config = {}
    
    # è·å–ç­–ç•¥ç½‘ç»œçš„çŠ¶æ€å­—å…¸
    policy_state_dict = None
    if 'policy_net_state_dict' in checkpoint:
        policy_state_dict = checkpoint['policy_net_state_dict']
    elif 'policy_net' in checkpoint:
        policy_state_dict = checkpoint['policy_net']
    
    if policy_state_dict is not None:
        # ä» stop_head æ¨æ–­å¿«é€’æŸœæ•°é‡
        # stop_head è¾“å‡ºç»´åº¦ = num_lockers + 1 (ä»“åº“)
        if 'stop_head.7.weight' in policy_state_dict:
            stop_output_dim = policy_state_dict['stop_head.7.weight'].shape[0]
            config['num_lockers'] = stop_output_dim - 1
            print(f"ğŸ” ä»æ¨¡å‹ç»“æ„æ¨æ–­: å¿«é€’æŸœæ•°é‡ = {config['num_lockers']} (stop_headè¾“å‡ºç»´åº¦: {stop_output_dim})")
        
        # ä» service_head éªŒè¯å¿«é€’æŸœæ•°é‡
        if 'service_head.7.weight' in policy_state_dict:
            service_output_dim = policy_state_dict['service_head.7.weight'].shape[0]
            inferred_lockers = service_output_dim
            if 'num_lockers' in config:
                if config['num_lockers'] != inferred_lockers:
                    print(f"âš ï¸  è­¦å‘Š: stop_headæ¨æ–­çš„å¿«é€’æŸœæ•°é‡({config['num_lockers']})ä¸service_headæ¨æ–­çš„({inferred_lockers})ä¸ä¸€è‡´")
                    # ä½¿ç”¨stop_headçš„ç»“æœï¼ˆæ›´å‡†ç¡®ï¼Œå› ä¸ºåŒ…å«ä»“åº“ï¼‰
            else:
                config['num_lockers'] = inferred_lockers
                print(f"ğŸ” ä»æ¨¡å‹ç»“æ„æ¨æ–­: å¿«é€’æŸœæ•°é‡ = {config['num_lockers']} (service_headè¾“å‡ºç»´åº¦: {service_output_dim})")
        
        # ä» state_encoder æ¨æ–­çŠ¶æ€ç»´åº¦
        if 'state_encoder.0.weight' in policy_state_dict:
            state_dim = policy_state_dict['state_encoder.0.weight'].shape[1]
            config['state_dim'] = state_dim
            print(f"ğŸ” ä»æ¨¡å‹ç»“æ„æ¨æ–­: çŠ¶æ€ç»´åº¦ = {state_dim}")
    
    # ä»checkpointä¸­è¯»å–ä¿å­˜çš„é…ç½®ä¿¡æ¯
    if 'num_trucks' in checkpoint:
        config['num_trucks'] = checkpoint['num_trucks']
        print(f"ğŸ“‹ ä»checkpointè¯»å–: å¡è½¦æ•°é‡ = {config['num_trucks']}")
    
    return config


def create_env_from_config(env_config: Dict[str, Any]) -> TruckSchedulingEnv:
    """
    æ ¹æ®é…ç½®åˆ›å»ºç¯å¢ƒ
    
    Args:
        env_config: ç¯å¢ƒé…ç½®å­—å…¸
        
    Returns:
        é…ç½®å¥½çš„ç¯å¢ƒå®ä¾‹
    """
    # åˆ›å»ºç¯å¢ƒ
    env = TruckSchedulingEnv(verbose=False)
    
    # å¦‚æœé…ç½®ä¸­æŒ‡å®šäº†å¿«é€’æŸœæ•°é‡ï¼Œæ›´æ–°ç¯å¢ƒé…ç½®
    if 'num_lockers' in env_config or 'num_trucks' in env_config:
        num_lockers = env_config.get('num_lockers', None)
        num_trucks = env_config.get('num_trucks', None)
        
        if num_lockers is not None:
            print(f"ğŸ”§ é…ç½®ç¯å¢ƒ: å¿«é€’æŸœæ•°é‡ = {num_lockers}")
        if num_trucks is not None:
            print(f"ğŸ”§ é…ç½®ç¯å¢ƒ: å¡è½¦æ•°é‡ = {num_trucks}")
        
        # ä½¿ç”¨ update_curriculum_config æ›´æ–°ç¯å¢ƒï¼ˆä½¿ç”¨configä¸­çš„å€¼ï¼‰
        curriculum_config = {
            'boundary': config.boundary,
            'demand_variance': config.demand_variance,
            'time_pressure': config.time_pressure
        }
        
        if num_lockers is not None:
            curriculum_config['num_lockers'] = num_lockers
        if num_trucks is not None:
            curriculum_config['num_trucks'] = num_trucks
        
        if hasattr(env, 'update_curriculum_config'):
            env.update_curriculum_config(curriculum_config)
        else:
            # å¦‚æœæ–¹æ³•ä¸å­˜åœ¨ï¼Œç›´æ¥ä¿®æ”¹é…ç½®
            # import config # Removed to avoid UnboundLocalError
            if num_lockers is not None:
                config.num_lockers = num_lockers
                config.generate_locker_info()
                env.num_lockers = num_lockers
                env.lockers_info = config.locker_info
            if num_trucks is not None:
                env.num_trucks = num_trucks
    
    # é‡ç½®ç¯å¢ƒä»¥åˆå§‹åŒ–æ‰€æœ‰å†…éƒ¨çŠ¶æ€ï¼ˆåŒ…æ‹¬å¡è½¦ã€æ€§èƒ½æŒ‡æ ‡ç­‰ï¼‰
    try:
        env.reset()
    except Exception as e:
        print(f"âš ï¸  ç¯å¢ƒé‡ç½®æ—¶å‡ºç°è­¦å‘Š: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œç¯å¢ƒå¯èƒ½å·²ç»éƒ¨åˆ†åˆå§‹åŒ–
    
    return env


def load_model(model_path: str, env: TruckSchedulingEnv = None) -> tuple:
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè‡ªåŠ¨æ¨æ–­ç¯å¢ƒé…ç½®
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        env: å¯é€‰çš„ç¯å¢ƒå®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä»æ¨¡å‹æ¨æ–­é…ç½®
        
    Returns:
        (mappo, env) å…ƒç»„ï¼ŒåŒ…å«åŠ è½½å¥½çš„MAPPOæ¨¡å‹å’Œé…ç½®å¥½çš„ç¯å¢ƒ
    """
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    # åŠ è½½checkpoint
    try:
        # å…¼å®¹æ–°ç‰ˆæœ¬PyTorchçš„weights_onlyå‚æ•°
        try:
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        except TypeError:
            # æ—§ç‰ˆæœ¬PyTorchä¸æ”¯æŒweights_onlyå‚æ•°
            checkpoint = torch.load(model_path, map_location='cpu')
    except Exception as e:
        raise RuntimeError(f"åŠ è½½æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
    
    # ä»æ¨¡å‹æ¨æ–­ç¯å¢ƒé…ç½®
    inferred_config = infer_env_config_from_model(checkpoint)
    
    # åˆ›å»ºæˆ–æ›´æ–°ç¯å¢ƒ
    if env is None:
        # ä»æ¨¡å‹æ¨æ–­é…ç½®åˆ›å»ºç¯å¢ƒ
        env = create_env_from_config(inferred_config)
    else:
        # æ£€æŸ¥ç¯å¢ƒé…ç½®æ˜¯å¦åŒ¹é…
        need_update = False
        if 'num_lockers' in inferred_config:
            if env.num_lockers != inferred_config['num_lockers']:
                print(f"âš ï¸  ç¯å¢ƒé…ç½®ä¸åŒ¹é…: å½“å‰ç¯å¢ƒæœ‰ {env.num_lockers} ä¸ªå¿«é€’æŸœï¼Œä½†æ¨¡å‹æ˜¯ä¸º {inferred_config['num_lockers']} ä¸ªå¿«é€’æŸœè®­ç»ƒçš„")
                need_update = True
        if 'num_trucks' in inferred_config:
            if env.num_trucks != inferred_config['num_trucks']:
                print(f"âš ï¸  ç¯å¢ƒé…ç½®ä¸åŒ¹é…: å½“å‰ç¯å¢ƒæœ‰ {env.num_trucks} è¾†å¡è½¦ï¼Œä½†æ¨¡å‹æ˜¯ä¸º {inferred_config['num_trucks']} è¾†å¡è½¦è®­ç»ƒçš„")
                need_update = True
        
        if need_update:
            print(f"   æ­£åœ¨æ›´æ–°ç¯å¢ƒé…ç½®ä»¥åŒ¹é…æ¨¡å‹...")
            env = create_env_from_config(inferred_config)
    
    # ç¡®ä¿ç¯å¢ƒå·²æ­£ç¡®åˆå§‹åŒ–ï¼ˆé‡ç½®ç¯å¢ƒï¼‰
    try:
        env.reset()
    except Exception as e:
        print(f"âš ï¸  ç¯å¢ƒé‡ç½®æ—¶å‡ºç°è­¦å‘Š: {e}")
    
    # è·å–ç¯å¢ƒå‚æ•°
    num_trucks = env.num_trucks
    
    # è·å–çŠ¶æ€ç»´åº¦ï¼ˆéœ€è¦å…ˆé‡ç½®ç¯å¢ƒï¼‰
    try:
        truck_states = env.get_truck_specific_states()
        state_dim = len(truck_states[0]) if truck_states else env.state_dim
    except Exception as e:
        # å¦‚æœè·å–çŠ¶æ€å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ¨æ–­çš„çŠ¶æ€ç»´åº¦
        print(f"âš ï¸  è·å–ç¯å¢ƒçŠ¶æ€æ—¶å‡ºé”™: {e}")
        if 'state_dim' in inferred_config:
            state_dim = inferred_config['state_dim']
            print(f"   ä½¿ç”¨ä»æ¨¡å‹æ¨æ–­çš„çŠ¶æ€ç»´åº¦: {state_dim}")
        else:
            # æœ€åå°è¯•ä½¿ç”¨ç¯å¢ƒçš„state_dimå±æ€§
            state_dim = getattr(env, 'state_dim', 422)
            print(f"   ä½¿ç”¨ç¯å¢ƒé»˜è®¤çŠ¶æ€ç»´åº¦: {state_dim}")
    
    # å¦‚æœä»æ¨¡å‹æ¨æ–­å‡ºäº†çŠ¶æ€ç»´åº¦ï¼Œä½¿ç”¨æ¨æ–­çš„å€¼
    if 'state_dim' in inferred_config:
        inferred_state_dim = inferred_config['state_dim']
        if state_dim != inferred_state_dim:
            print(f"âš ï¸  çŠ¶æ€ç»´åº¦ä¸åŒ¹é…: å½“å‰ç¯å¢ƒçŠ¶æ€ç»´åº¦ä¸º {state_dim}ï¼Œä½†æ¨¡å‹æœŸæœ› {inferred_state_dim}")
            print(f"   ä½¿ç”¨æ¨¡å‹æœŸæœ›çš„çŠ¶æ€ç»´åº¦: {inferred_state_dim}")
            state_dim = inferred_state_dim
    
    action_dim = {
        "select_stop": env.num_lockers + 1,  # 0:ä»“åº“, 1-n:å¿«é€’æŸœ
        "service_area": env.num_lockers  # æ¯ä¸ªå¿«é€’æŸœä¸€ä¸ªäºŒè¿›åˆ¶é€‰æ‹©
    }
    
    print(f"\nğŸ”§ æœ€ç»ˆç¯å¢ƒé…ç½®:")
    print(f"   - å¡è½¦æ•°é‡: {num_trucks}")
    print(f"   - å¿«é€’æŸœæ•°é‡: {env.num_lockers}")
    print(f"   - çŠ¶æ€ç»´åº¦: {state_dim}")
    print(f"   - åŠ¨ä½œç»´åº¦: {action_dim}")
    
    # åˆ›å»ºMAPPOå®ä¾‹
    mappo = MAPPO(num_trucks, state_dim, action_dim, lr=config.LEARNING_RATE)
    
    # åŠ è½½æ¨¡å‹æƒé‡
    try:
        # æ£€æŸ¥checkpointçš„ç»“æ„
        if isinstance(checkpoint, dict):
            # æ£€æŸ¥ä¸åŒçš„é”®åæ ¼å¼
            if 'policy_net_state_dict' in checkpoint and 'value_net_state_dict' in checkpoint:
                mappo.policy_net.load_state_dict(checkpoint['policy_net_state_dict'], strict=False)
                mappo.value_net.load_state_dict(checkpoint['value_net_state_dict'], strict=False)
                print("âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡ (policy_net_state_dict, value_net_state_dict)")
            elif 'policy_net' in checkpoint and 'value_net' in checkpoint:
                mappo.policy_net.load_state_dict(checkpoint['policy_net'], strict=False)
                mappo.value_net.load_state_dict(checkpoint['value_net'], strict=False)
                print("âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡ (policy_net, value_net)")
            else:
                raise ValueError(f"æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸åŒ¹é…ï¼Œå¯ç”¨é”®: {list(checkpoint.keys())}")
        else:
            raise ValueError("æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
        
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        mappo.policy_net.eval()
        mappo.value_net.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'num_trucks' in checkpoint:
            print(f"   - æ¨¡å‹è®­ç»ƒæ—¶çš„å¡è½¦æ•°é‡: {checkpoint['num_trucks']}")
        if 'episode' in checkpoint:
            print(f"   - æ¨¡å‹è®­ç»ƒè½®æ•°: {checkpoint['episode']}")
        if 'best_avg_reward' in checkpoint:
            print(f"   - æ¨¡å‹æœ€ä½³å¹³å‡å¥–åŠ±: {checkpoint['best_avg_reward']:.2f}")
        if 'episode_reward' in checkpoint:
            print(f"   - æ¨¡å‹ä¿å­˜æ—¶çš„å¥–åŠ±: {checkpoint['episode_reward']:.2f}")
            
    except Exception as e:
        raise RuntimeError(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    
    return mappo, env


def run_test_episode(env: TruckSchedulingEnv, mappo: MAPPO, episode_num: int, verbose: bool = True) -> Dict[str, Any]:
    """
    è¿è¡Œä¸€ä¸ªæµ‹è¯•å›åˆ
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        mappo: MAPPOæ¨¡å‹
        episode_num: å›åˆç¼–å·
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
    Returns:
        åŒ…å«æµ‹è¯•ç»“æœçš„å­—å…¸
    """
    # é‡ç½®ç¯å¢ƒ
    state, action_mask = env.reset()
    episode_reward = 0.0
    step_count = 0
    done = False
    
    # è®°å½•æ¯æ­¥çš„å¥–åŠ±
    step_rewards = []
    
    if verbose:
        print(f"\nğŸ® å¼€å§‹æµ‹è¯•å›åˆ {episode_num + 1}")
    
    while not done and step_count < env.max_timesteps:
        # è·å–åŠ¨ä½œæ©ç 
        action_masks = env.get_action_masks()
        
        # è·å–æ¯ä¸ªå¡è½¦çš„ç‰¹å®šçŠ¶æ€
        truck_states = env.get_truck_specific_states()
        
        # ä½¿ç”¨æ¨¡å‹é€‰æ‹©åŠ¨ä½œï¼ˆä¸æ·»åŠ æ¢ç´¢å™ªå£°ï¼‰
        with torch.no_grad():
            actions, log_probs, values = mappo.act(truck_states, action_masks, env)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_state, rewards, done, next_action_mask = env.step(actions)
        
        # ç´¯ç§¯å¥–åŠ±
        if isinstance(rewards, list):
            step_reward = sum(rewards)
            episode_reward += step_reward
            step_rewards.append(step_reward)
        else:
            episode_reward += rewards
            step_rewards.append(rewards)
        
        # æ›´æ–°çŠ¶æ€
        state = next_state
        action_mask = next_action_mask
        step_count += 1
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    completion_rate = env._calculate_completion_rate()
    path_efficiency = env._calculate_path_efficiency()
    capacity_utilization = env._calculate_capacity_utilization()
    
    # è®¡ç®—æ€»éœ€æ±‚å’ŒæœåŠ¡æƒ…å†µ
    total_demand_del = sum(locker.get('demand_del', 0) for locker in env.lockers_state)
    total_demand_ret = sum(locker.get('demand_ret', 0) for locker in env.lockers_state)
    total_demand = total_demand_del + total_demand_ret
    
    total_served_del = sum(locker.get('served_demand_del', 0) for locker in env.lockers_state)
    total_served_ret = sum(locker.get('served_demand_ret', 0) for locker in env.lockers_state)
    total_served = total_served_del + total_served_ret
    
    served_rate = (total_served / total_demand * 100) if total_demand > 0 else 0.0
    
    result = {
        'episode': episode_num + 1,
        'episode_reward': episode_reward,
        'step_count': step_count,
        'completion_rate': completion_rate,
        'path_efficiency': path_efficiency,
        'capacity_utilization': capacity_utilization,
        'total_demand': total_demand,
        'total_served': total_served,
        'served_rate': served_rate,
        'avg_step_reward': np.mean(step_rewards) if step_rewards else 0.0,
        'max_step_reward': np.max(step_rewards) if step_rewards else 0.0,
        'min_step_reward': np.min(step_rewards) if step_rewards else 0.0
    }
    
    if verbose:
        print(f"   âœ… å›åˆå®Œæˆ")
        print(f"      - æ€»å¥–åŠ±: {episode_reward:.2f}")
        print(f"      - æ­¥æ•°: {step_count}")
        print(f"      - å®Œæˆç‡: {completion_rate:.2f}%")
        print(f"      - è·¯å¾„æ•ˆç‡: {path_efficiency:.2f}%")
        print(f"      - å®¹é‡åˆ©ç”¨ç‡: {capacity_utilization:.2f}%")
        print(f"      - æœåŠ¡ç‡: {served_rate:.2f}% ({total_served}/{total_demand})")
    
    return result


def run_tests(model_path: str = "trained_mappo_policy.pth", num_episodes: int = 5, verbose: bool = True) -> Dict[str, Any]:
    """
    è¿è¡Œæµ‹è¯•
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        num_episodes: æµ‹è¯•å›åˆæ•°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
    Returns:
        æµ‹è¯•ç»“æœæ±‡æ€»
    """
    print("=" * 60)
    print("ğŸ§ª MAPPOæ¨¡å‹å¿«é€Ÿæµ‹è¯•")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨æ¨æ–­ç¯å¢ƒé…ç½®ï¼‰
    print("\nğŸ“‚ åŠ è½½æ¨¡å‹å¹¶æ¨æ–­ç¯å¢ƒé…ç½®...")
    try:
        mappo, env = load_model(model_path, env=None)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {'status': 'error', 'error': str(e)}
    
    print(f"\nğŸ“Š æœ€ç»ˆç¯å¢ƒé…ç½®:")
    print(f"   - å¡è½¦æ•°é‡: {env.num_trucks}")
    print(f"   - å¿«é€’æŸœæ•°é‡: {env.num_lockers}")
    print(f"   - å¡è½¦å®¹é‡: {env.truck_capacity}")
    print(f"   - æœ€å¤§æ­¥æ•°: {env.max_timesteps}")
    print(f"   - æ— äººæœºèˆªç¨‹: {config.DRONE_MAX_RANGE}")
    
    # è¿è¡Œæµ‹è¯•
    print(f"\nğŸš€ å¼€å§‹è¿è¡Œ {num_episodes} ä¸ªæµ‹è¯•å›åˆ...")
    print("=" * 60)
    
    test_results = []
    for i in range(num_episodes):
        result = run_test_episode(env, mappo, i, verbose=verbose)
        test_results.append(result)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    episode_rewards = [r['episode_reward'] for r in test_results]
    completion_rates = [r['completion_rate'] for r in test_results]
    path_efficiencies = [r['path_efficiency'] for r in test_results]
    capacity_utilizations = [r['capacity_utilization'] for r in test_results]
    served_rates = [r['served_rate'] for r in test_results]
    step_counts = [r['step_count'] for r in test_results]
    
    summary = {
        'status': 'success',
        'num_episodes': num_episodes,
        'episode_rewards': {
            'mean': np.mean(episode_rewards),
            'std': np.std(episode_rewards),
            'min': np.min(episode_rewards),
            'max': np.max(episode_rewards)
        },
        'completion_rates': {
            'mean': np.mean(completion_rates),
            'std': np.std(completion_rates),
            'min': np.min(completion_rates),
            'max': np.max(completion_rates)
        },
        'path_efficiencies': {
            'mean': np.mean(path_efficiencies),
            'std': np.std(path_efficiencies),
            'min': np.min(path_efficiencies),
            'max': np.max(path_efficiencies)
        },
        'capacity_utilizations': {
            'mean': np.mean(capacity_utilizations),
            'std': np.std(capacity_utilizations),
            'min': np.min(capacity_utilizations),
            'max': np.max(capacity_utilizations)
        },
        'served_rates': {
            'mean': np.mean(served_rates),
            'std': np.std(served_rates),
            'min': np.min(served_rates),
            'max': np.max(served_rates)
        },
        'step_counts': {
            'mean': np.mean(step_counts),
            'std': np.std(step_counts),
            'min': np.min(step_counts),
            'max': np.max(step_counts)
        },
        'detailed_results': test_results
    }
    
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœæ±‡æ€»
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"\nğŸ¯ å¥–åŠ±ç»Ÿè®¡ ({num_episodes} å›åˆ):")
    print(f"   - å¹³å‡å¥–åŠ±: {summary['episode_rewards']['mean']:.2f} Â± {summary['episode_rewards']['std']:.2f}")
    print(f"   - æœ€ä½³å¥–åŠ±: {summary['episode_rewards']['max']:.2f}")
    print(f"   - æœ€å·®å¥–åŠ±: {summary['episode_rewards']['min']:.2f}")
    
    print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    print(f"   - å¹³å‡å®Œæˆç‡: {summary['completion_rates']['mean']:.2f}% Â± {summary['completion_rates']['std']:.2f}%")
    print(f"   - å¹³å‡è·¯å¾„æ•ˆç‡: {summary['path_efficiencies']['mean']:.2f}% Â± {summary['path_efficiencies']['std']:.2f}%")
    print(f"   - å¹³å‡å®¹é‡åˆ©ç”¨ç‡: {summary['capacity_utilizations']['mean']:.2f}% Â± {summary['capacity_utilizations']['std']:.2f}%")
    print(f"   - å¹³å‡æœåŠ¡ç‡: {summary['served_rates']['mean']:.2f}% Â± {summary['served_rates']['std']:.2f}%")
    
    print(f"\nâ±ï¸  æ­¥æ•°ç»Ÿè®¡:")
    print(f"   - å¹³å‡æ­¥æ•°: {summary['step_counts']['mean']:.1f} Â± {summary['step_counts']['std']:.1f}")
    print(f"   - æœ€å°‘æ­¥æ•°: {summary['step_counts']['min']}")
    print(f"   - æœ€å¤šæ­¥æ•°: {summary['step_counts']['max']}")
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("=" * 60)
    
    return summary


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='MAPPOæ¨¡å‹å¿«é€Ÿæµ‹è¯•è„šæœ¬')
    parser.add_argument('--model', type=str, default='trained_mappo_policy.pth',
                        help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: trained_mappo_policy.pth)')
    parser.add_argument('--episodes', type=int, default=5,
                        help='æµ‹è¯•å›åˆæ•° (é»˜è®¤: 5)')
    parser.add_argument('--quiet', action='store_true',
                        help='é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print(f"   è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        print(f"   å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶:")
        for file in os.listdir('.'):
            if file.endswith('.pth'):
                print(f"      - {file}")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    try:
        summary = run_tests(
            model_path=args.model,
            num_episodes=args.episodes,
            verbose=not args.quiet
        )
        
        if summary['status'] == 'success':
            sys.exit(0)
        else:
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

