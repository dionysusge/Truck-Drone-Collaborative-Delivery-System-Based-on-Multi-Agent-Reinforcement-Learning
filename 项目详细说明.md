# é¡¹ç›®è¯¦ç»†è¯´æ˜æ–‡æ¡£

## ğŸ“‹ æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜é¡¹ç›®ä¸­ä¸ `start_training.py` ç›¸å…³çš„æ‰€æœ‰ Python æ–‡ä»¶çš„åŠŸèƒ½ã€ç±»ã€æ–¹æ³•å’Œå®ç°ç»†èŠ‚ã€‚

---

## ğŸš€ æ ¸å¿ƒè®­ç»ƒæ–‡ä»¶

### 1. `start_training.py` - è®­ç»ƒå¯åŠ¨ä¸ç®¡ç†è„šæœ¬

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/start_training.py`  
**è¡Œæ•°**ï¼š964è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šMAPPOè®­ç»ƒå¯åŠ¨ã€è®­ç»ƒè¿‡ç¨‹ç®¡ç†ã€æ€§èƒ½ç›‘æ§ã€å¯è§†åŒ–

#### 1.1 ä¸»è¦ç±»

##### `CustomJSONEncoder`
**åŠŸèƒ½**ï¼šè‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†ä¸å¯åºåˆ—åŒ–çš„ç±»å‹ï¼ˆnumpyã€torchç­‰ï¼‰

**æ–¹æ³•**ï¼š
- `default(obj)`: å¤„ç†ç‰¹æ®Šç±»å‹çš„åºåˆ—åŒ–

##### `AdaptiveLearningRateScheduler`
**åŠŸèƒ½**ï¼šè‡ªé€‚åº”å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œæ ¹æ®è®­ç»ƒè¿›åº¦åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `initial_lr`: åˆå§‹å­¦ä¹ ç‡ï¼ˆé»˜è®¤3e-4ï¼‰
- `min_lr`: æœ€å°å­¦ä¹ ç‡ï¼ˆé»˜è®¤1e-5ï¼‰
- `patience`: æ€§èƒ½åœæ»å®¹å¿è½®æ•°ï¼ˆé»˜è®¤100ï¼‰
- `decay_factor`: è¡°å‡å› å­ï¼ˆé»˜è®¤0.8ï¼‰

**ä¸»è¦æ–¹æ³•**ï¼š
- `update(current_reward, episode)`: æ ¹æ®å½“å‰å¥–åŠ±æ›´æ–°å­¦ä¹ ç‡
  - å¦‚æœæ€§èƒ½æå‡ï¼Œé‡ç½®patienceè®¡æ•°å™¨
  - å¦‚æœæ€§èƒ½åœæ»è¶…è¿‡patienceè½®ï¼Œé™ä½å­¦ä¹ ç‡

##### `ExplorationScheduler`
**åŠŸèƒ½**ï¼šæ¢ç´¢ç­–ç•¥è°ƒåº¦å™¨ï¼ŒåŠ¨æ€è°ƒæ•´æ¢ç´¢å‚æ•°

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `initial_epsilon`: åˆå§‹æ¢ç´¢ç‡ï¼ˆé»˜è®¤0.3ï¼‰
- `min_epsilon`: æœ€å°æ¢ç´¢ç‡ï¼ˆé»˜è®¤0.05ï¼‰
- `decay_rate`: è¡°å‡ç‡ï¼ˆé»˜è®¤0.995ï¼‰
- `entropy_coef_initial`: åˆå§‹ç†µç³»æ•°ï¼ˆé»˜è®¤0.01ï¼‰

**ä¸»è¦æ–¹æ³•**ï¼š
- `update(episode, performance_variance)`: æ›´æ–°æ¢ç´¢å‚æ•°
  - åŸºäºè½®æ•°è¡°å‡epsilon
  - åŸºäºæ€§èƒ½æ–¹å·®è°ƒæ•´ç†µç³»æ•°ï¼ˆé«˜æ–¹å·®å¢åŠ æ¢ç´¢ï¼‰

##### `RewardSmoother`
**åŠŸèƒ½**ï¼šå¥–åŠ±å¹³æ»‘å™¨ï¼Œä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡å¹³æ»‘å¥–åŠ±ä¿¡å·

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `alpha`: æŒ‡æ•°ç§»åŠ¨å¹³å‡ç³»æ•°ï¼ˆé»˜è®¤0.1ï¼‰
- `outlier_threshold`: å¼‚å¸¸å€¼æ£€æµ‹é˜ˆå€¼ï¼ˆé»˜è®¤2.0å€æ ‡å‡†å·®ï¼‰

**ä¸»è¦æ–¹æ³•**ï¼š
- `smooth(reward)`: å¹³æ»‘å¥–åŠ±å€¼
  - å¼‚å¸¸å€¼æ£€æµ‹ï¼šå¦‚æœå¥–åŠ±åç¦»å‡å€¼è¶…è¿‡é˜ˆå€¼ï¼Œä½¿ç”¨å‡å€¼æ›¿ä»£
  - æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼š$EMA = \alpha \times reward + (1-\alpha) \times EMA_{prev}$

##### `ConvergenceDetector`
**åŠŸèƒ½**ï¼šæ”¶æ•›æ£€æµ‹å™¨ï¼Œæ£€æµ‹è®­ç»ƒæ˜¯å¦æ”¶æ•›æˆ–é™·å…¥å±€éƒ¨æœ€ä¼˜

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `window_size`: æ£€æµ‹çª—å£å¤§å°ï¼ˆé»˜è®¤50ï¼‰
- `stability_threshold`: ç¨³å®šæ€§é˜ˆå€¼ï¼ˆé»˜è®¤0.05ï¼‰
- `improvement_threshold`: æ”¹è¿›é˜ˆå€¼ï¼ˆé»˜è®¤0.01ï¼‰

**ä¸»è¦æ–¹æ³•**ï¼š
- `check_convergence(reward)`: æ£€æŸ¥æ”¶æ•›çŠ¶æ€
  - è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆCV = std/meanï¼‰
  - è®¡ç®—æ”¹è¿›ç‡ï¼ˆæœ€è¿‘çª—å£ vs æ—©æœŸçª—å£ï¼‰
  - è¿”å›æ”¶æ•›çŠ¶æ€ï¼š'converged', 'converging_with_improvement', 'degrading', 'local_optimum', 'training'

##### `TrainingManager`
**åŠŸèƒ½**ï¼šè®­ç»ƒç®¡ç†å™¨ï¼Œç®¡ç†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `env`: è®­ç»ƒç¯å¢ƒï¼ˆTruckSchedulingEnvï¼‰
- `enable_optimization`: æ˜¯å¦å¯ç”¨è®­ç»ƒç¨³å®šæ€§ä¼˜åŒ–ï¼ˆé»˜è®¤Trueï¼‰

**ä¸»è¦æ–¹æ³•**ï¼š
- `log_training_progress(episode, reward, metrics)`: è®°å½•è®­ç»ƒè¿›åº¦
  - åº”ç”¨å¥–åŠ±å¹³æ»‘
  - æ›´æ–°å­¦ä¹ ç‡
  - æ›´æ–°æ¢ç´¢å‚æ•°
  - æ£€æŸ¥æ”¶æ•›çŠ¶æ€
  
- `get_current_training_params()`: è·å–å½“å‰è®­ç»ƒå‚æ•°ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´ï¼‰

- `evaluate_training_performance()`: è¯„ä¼°è®­ç»ƒæ€§èƒ½
  - è®¡ç®—å¹³å‡å¥–åŠ±ã€æœ€ä½³å¥–åŠ±ã€å¥–åŠ±æ”¹è¿›ç‡
  - è¿”å›æ€§èƒ½è¯„ä¼°å­—å…¸

- `save_training_report(filename)`: ä¿å­˜è®­ç»ƒæŠ¥å‘Š
  - ç”ŸæˆJSONæ ¼å¼çš„å®Œæ•´è®­ç»ƒæŠ¥å‘Š
  - åŒ…å«è®­ç»ƒæ‘˜è¦ã€ç¯å¢ƒé…ç½®ã€è®­ç»ƒé…ç½®ã€è®­ç»ƒæ—¥å¿—ã€ä¼˜åŒ–å†å²

- `generate_training_plots(save_dir)`: ç”Ÿæˆè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å›¾è¡¨
  - å¹³å‡å¥–åŠ±æ”¶æ•›æ›²çº¿ï¼ˆå¸¦è¶‹åŠ¿çº¿ï¼‰
  - æŸå¤±å‡½æ•°åˆ†æå›¾è¡¨ï¼ˆç­–ç•¥æŸå¤±ã€ä»·å€¼æŸå¤±ï¼‰

#### 1.2 ä¸»è¦å‡½æ•°

##### `run_training_session(num_episodes, enable_optimization)`
**åŠŸèƒ½**ï¼šè¿è¡Œå®Œæ•´çš„è®­ç»ƒä¼šè¯

**æµç¨‹**ï¼š
1. åˆ›å»ºè®­ç»ƒç¯å¢ƒï¼ˆTruckSchedulingEnvï¼‰
2. è®¾ç½®ç¯å¢ƒé…ç½®ï¼ˆå¿«é€’æŸœæ•°é‡ã€è¾¹ç•ŒèŒƒå›´ç­‰ï¼‰
3. åˆ›å»ºè®­ç»ƒç®¡ç†å™¨ï¼ˆTrainingManagerï¼‰
4. è°ƒç”¨ `train_marl()` å¼€å§‹è®­ç»ƒ
5. ä¿å­˜æ¨¡å‹ï¼ˆtrained_mappo_policy.pthï¼‰
6. ç”Ÿæˆè®­ç»ƒå›¾è¡¨å’ŒæŠ¥å‘Š
7. è¿”å›è®­ç»ƒç»“æœ

**è¿”å›**ï¼š
```python
{
    'status': 'success' or 'error',
    'performance': {...},
    'model_path': 'trained_mappo_policy.pth',
    'trained_policy': MAPPOå¯¹è±¡,
    'optimization_enabled': bool
}
```

##### `quick_training_test()`
**åŠŸèƒ½**ï¼šå¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ŒéªŒè¯è®­ç»ƒæµç¨‹æ˜¯å¦æ­£å¸¸

**å®ç°**ï¼šè¿è¡Œ1500è½®è®­ç»ƒæµ‹è¯•

##### `main()`
**åŠŸèƒ½**ï¼šä¸»å‡½æ•°ï¼Œæ‰§è¡Œå¿«é€Ÿæµ‹è¯•å’Œæ­£å¼è®­ç»ƒ

---

### 2. `truck_routing.py` - æ ¸å¿ƒç®—æ³•ä¸ç¯å¢ƒå®ç°

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/truck_routing.py`  
**è¡Œæ•°**ï¼šçº¦4600è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šç¯å¢ƒä»¿çœŸã€MAPPOç®—æ³•å®ç°ã€è¯¾ç¨‹å­¦ä¹ ã€è®­ç»ƒå‡½æ•°

#### 2.1 è¯¾ç¨‹å­¦ä¹ æ¨¡å—

##### `DifficultyLevel` (Enum)
**åŠŸèƒ½**ï¼šå®šä¹‰éš¾åº¦ç­‰çº§
- BEGINNER, EASY, MEDIUM, HARD, EXPERT

##### `CurriculumStage` (dataclass)
**åŠŸèƒ½**ï¼šè¯¾ç¨‹å­¦ä¹ é˜¶æ®µé…ç½®
- `name`: é˜¶æ®µåç§°
- `num_lockers`: å¿«é€’æŸœæ•°é‡
- `num_trucks`: å¡è½¦æ•°é‡
- `boundary`: è¾¹ç•ŒèŒƒå›´
- `difficulty`: éš¾åº¦ç­‰çº§

##### `CurriculumManager`
**åŠŸèƒ½**ï¼šè¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ï¼Œå®ç°æ¸è¿›å¼éš¾åº¦è°ƒæ•´

**ä¸»è¦æ–¹æ³•**ï¼š
- `get_current_config()`: è·å–å½“å‰é…ç½®
- `update_stage(performance)`: æ ¹æ®æ€§èƒ½æ›´æ–°é˜¶æ®µ
- `should_progress()`: åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
- `should_regress()`: åˆ¤æ–­æ˜¯å¦åº”è¯¥å›é€€åˆ°ä¸Šä¸€é˜¶æ®µ

#### 2.2 ç¯å¢ƒç±»

##### `TruckSchedulingEnv`
**åŠŸèƒ½**ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå®ç°Gymæ¥å£

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `verbose`: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯

**æ ¸å¿ƒå±æ€§**ï¼š
- `num_trucks`: å¡è½¦æ•°é‡ï¼ˆåŠ¨æ€è®¡ç®—ï¼‰
- `num_lockers`: å¿«é€’æŸœæ•°é‡ï¼ˆé»˜è®¤50ï¼‰
- `truck_capacity`: å¡è½¦å®¹é‡ï¼ˆ100ï¼‰
- `drone_max_range`: æ— äººæœºæœ€å¤§èˆªç¨‹ï¼ˆ50ï¼‰
- `max_timesteps`: æœ€å¤§æ—¶é—´æ­¥æ•°ï¼ˆ600ï¼‰

**æ ¸å¿ƒæ–¹æ³•**ï¼š
- `reset()`: é‡ç½®ç¯å¢ƒï¼Œè¿”å›åˆå§‹çŠ¶æ€
- `step(actions)`: æ‰§è¡ŒåŠ¨ä½œï¼Œè¿”å›(next_state, rewards, done, info)
- `get_action_masks()`: è·å–åŠ¨ä½œæ©ç ï¼Œè¿‡æ»¤æ— æ•ˆåŠ¨ä½œ
- `get_truck_specific_states()`: è·å–æ¯ä¸ªå¡è½¦çš„ç‹¬ç«‹çŠ¶æ€
- `_calculate_completion_rate()`: è®¡ç®—æœåŠ¡å®Œæˆç‡
- `_calculate_path_efficiency()`: è®¡ç®—è·¯å¾„æ•ˆç‡
- `_calculate_capacity_utilization()`: è®¡ç®—å®¹é‡åˆ©ç”¨ç‡

**çŠ¶æ€ç©ºé—´**ï¼š
- ç»´åº¦ï¼šçº¦400-600ç»´ï¼ˆå–å†³äºå¿«é€’æŸœæ•°é‡ï¼‰
- ç»„æˆï¼šå±€éƒ¨ç‰¹å¾ + å…¨å±€ç‰¹å¾ + æ—¶ç©ºç‰¹å¾ + åŠ¨æ€ç‰¹å¾

**åŠ¨ä½œç©ºé—´**ï¼š
- `select_stop`: N+1ä¸ªé€‰æ‹©ï¼ˆNä¸ªå¿«é€’æŸœ + 1ä¸ªä»“åº“ï¼‰
- `service_area`: Nä¸ªäºŒè¿›åˆ¶é€‰æ‹©ï¼ˆæ¯ä¸ªå¿«é€’æŸœæ˜¯å¦æœåŠ¡ï¼‰

#### 2.3 ç¥ç»ç½‘ç»œç±»

##### `TruckPolicyNetwork`
**åŠŸèƒ½**ï¼šå¡è½¦ç­–ç•¥ç½‘ç»œï¼Œä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶

**ç½‘ç»œç»“æ„**ï¼š
- çŠ¶æ€ç¼–ç å™¨ï¼šå¤šå±‚å…¨è¿æ¥ç½‘ç»œ
- å¤šå¤´æ³¨æ„åŠ›å±‚ï¼šå¤„ç†å¿«é€’æŸœä¹‹é—´çš„å…³ç³»
- åœé ç‚¹å¤´ï¼šè¾“å‡ºåœé ç‚¹é€‰æ‹©æ¦‚ç‡
- æœåŠ¡åŒºåŸŸå¤´ï¼šè¾“å‡ºæœåŠ¡åŒºåŸŸé€‰æ‹©æ¦‚ç‡

**å…³é”®ç‰¹æ€§**ï¼š
- æ”¯æŒåŠ¨ä½œæ©ç 
- LayerNormæ ‡å‡†åŒ–
- Dropoutæ­£åˆ™åŒ–

##### `RouteAwareValueNetwork`
**åŠŸèƒ½**ï¼šè·¯å¾„æ„ŸçŸ¥ä»·å€¼ç½‘ç»œï¼Œä¼°è®¡çŠ¶æ€ä»·å€¼

**ç½‘ç»œç»“æ„**ï¼š
- çŠ¶æ€ç¼–ç å™¨
- è·¯å¾„ç‰¹å¾æå–
- ä»·å€¼ä¼°è®¡å¤´

##### `MAPPO`
**åŠŸèƒ½**ï¼šMulti-Agent Proximal Policy Optimizationç®—æ³•å®ç°

**æ ¸å¿ƒç»„ä»¶**ï¼š
- `policy_net`: ç­–ç•¥ç½‘ç»œ
- `value_net`: ä»·å€¼ç½‘ç»œ
- `policy_optimizer`: ç­–ç•¥ä¼˜åŒ–å™¨
- `value_optimizer`: ä»·å€¼ä¼˜åŒ–å™¨

**ä¸»è¦æ–¹æ³•**ï¼š
- `act(states, action_masks, env)`: é€‰æ‹©åŠ¨ä½œ
- `update(rollouts)`: æ›´æ–°ç­–ç•¥å’Œä»·å€¼ç½‘ç»œ
- `compute_gae(rewards, values, dones)`: è®¡ç®—GAEä¼˜åŠ¿
- `update_hyperparameters(params)`: æ›´æ–°è¶…å‚æ•°

**å…³é”®å‚æ•°**ï¼š
- `clip_ratio`: PPOè£å‰ªèŒƒå›´ï¼ˆé»˜è®¤0.05ï¼‰
- `entropy_coef`: ç†µç³»æ•°ï¼ˆé»˜è®¤0.02ï¼‰
- `value_coef`: ä»·å€¼å‡½æ•°æƒé‡ï¼ˆé»˜è®¤0.5ï¼‰
- `max_grad_norm`: æœ€å¤§æ¢¯åº¦èŒƒæ•°ï¼ˆé»˜è®¤0.3ï¼‰

#### 2.4 è®­ç»ƒå‡½æ•°

##### `train_marl(env, num_episodes, training_manager, ...)`
**åŠŸèƒ½**ï¼šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸»å‡½æ•°

**å‚æ•°**ï¼š
- `env`: è®­ç»ƒç¯å¢ƒ
- `num_episodes`: è®­ç»ƒè½®æ•°
- `training_manager`: è®­ç»ƒç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
- `curriculum_manager`: è¯¾ç¨‹å­¦ä¹ ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
- `optimized_config`: ä¼˜åŒ–çš„è®­ç»ƒé…ç½®ï¼ˆå¯é€‰ï¼‰

**è®­ç»ƒæµç¨‹**ï¼š
1. åˆ›å»ºMAPPOå®ä¾‹
2. åˆå§‹åŒ–ç»éªŒç¼“å†²åŒº
3. è®­ç»ƒå¾ªç¯ï¼š
   - æ”¶é›†ç»éªŒï¼ˆrolloutï¼‰
   - è®¡ç®—GAEä¼˜åŠ¿
   - æ›´æ–°ç­–ç•¥å’Œä»·å€¼ç½‘ç»œï¼ˆå¤šè½®æ›´æ–°ï¼‰
   - è®°å½•è®­ç»ƒè¿›åº¦
4. éªŒè¯è¯„ä¼°ï¼ˆå®šæœŸï¼‰
5. æ—©åœæ£€æµ‹

**è¿”å›**ï¼šè®­ç»ƒå¥½çš„MAPPOå¯¹è±¡

##### `validate_model(mappo, validation_env, num_validation_episodes)`
**åŠŸèƒ½**ï¼šéªŒè¯æ¨¡å‹æ€§èƒ½

---

### 3. `reward_function.py` - å¥–åŠ±å‡½æ•°å®ç°

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/reward_function.py`  
**è¡Œæ•°**ï¼š651è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šè®¡ç®—ç»¼åˆå¥–åŠ±ï¼Œå°†å¤šç›®æ ‡ä¼˜åŒ–è½¬åŒ–ä¸ºå¥–åŠ±ä¿¡å·

#### 3.1 ä¸»è¦ç±»

##### `RewardFunction`
**åŠŸèƒ½**ï¼šç®€åŒ–æ•´åˆçš„å¥–åŠ±å‡½æ•°

**å¥–åŠ±æƒé‡ç»“æ„**ï¼ˆ5å¤§ç±»ï¼‰ï¼š
1. **æœåŠ¡å®Œæˆå¥–åŠ±**ï¼š
   - `service_completion`: 0
   - `demand_satisfaction`: 0.001
   - `early_completion_bonus`: 5.0

2. **è¿è¥æ•ˆç‡å¥–åŠ±**ï¼š
   - `operational_efficiency`: 60.0
   - `demand_weighted_efficiency`: 50.0ï¼ˆæ ¸å¿ƒï¼‰
   - `resource_utilization`: 15.0
   - `coordination_bonus`: 100.0

3. **æˆæœ¬æ§åˆ¶æƒ©ç½š**ï¼š
   - `travel_cost_penalty`: 12.0
   - `time_cost_penalty`: 3.0
   - `step_penalty`: 25.0

4. **çº¦æŸè¿è§„æƒ©ç½š**ï¼š
   - `constraint_violation`: 3.0
   - `invalid_action_penalty`: 2.0
   - `unserved_demand_penalty`: 1.0

5. **ç­–ç•¥ä¼˜åŒ–å¥–åŠ±**ï¼š
   - `strategic_decision`: 35.0
   - `coverage_optimization`: 30.0

**ä¸»è¦æ–¹æ³•**ï¼š
- `calculate_reward(action, state_before, state_after, done, truck_id, timestep)`: è®¡ç®—ç»¼åˆå¥–åŠ±
  - è°ƒç”¨5ä¸ªå­å‡½æ•°è®¡ç®—å„ç±»å¥–åŠ±
  - è¿”å›æ€»å¥–åŠ±å’Œå¥–åŠ±åˆ†è§£

- `_calculate_service_completion_reward(...)`: è®¡ç®—æœåŠ¡å®Œæˆå¥–åŠ±
- `_calculate_operational_efficiency_reward(...)`: è®¡ç®—è¿è¥æ•ˆç‡å¥–åŠ±
- `_calculate_cost_control_penalty(...)`: è®¡ç®—æˆæœ¬æ§åˆ¶æƒ©ç½š
- `_calculate_constraint_violation_penalty(...)`: è®¡ç®—çº¦æŸè¿è§„æƒ©ç½š
- `_calculate_strategic_optimization_reward(...)`: è®¡ç®—ç­–ç•¥ä¼˜åŒ–å¥–åŠ±

##### `AdaptiveRewardScheduler`
**åŠŸèƒ½**ï¼šè‡ªé€‚åº”å¥–åŠ±è°ƒåº¦å™¨ï¼ŒåŠ¨æ€è°ƒæ•´å¥–åŠ±æƒé‡

**ä¸»è¦æ–¹æ³•**ï¼š
- `update_weights(performance_metrics)`: æ ¹æ®æ€§èƒ½æŒ‡æ ‡æ›´æ–°æƒé‡
- `get_current_weights()`: è·å–å½“å‰æƒé‡

---

### 4. `state_representation.py` - çŠ¶æ€è¡¨ç¤º

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/state_representation.py`  
**è¡Œæ•°**ï¼š1493è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šå°†ç¯å¢ƒçŠ¶æ€ç¼–ç ä¸ºç¥ç»ç½‘ç»œå¯å¤„ç†çš„å‘é‡

#### 4.1 ä¸»è¦ç±»

##### `StateRepresentation`
**åŠŸèƒ½**ï¼šå¤šå±‚æ¬¡çŠ¶æ€è¡¨ç¤ºï¼Œæå–å±€éƒ¨ã€å…¨å±€ã€æ—¶ç©ºã€åŠ¨æ€ç‰¹å¾

**ç‰¹å¾ç»„æˆ**ï¼š
1. **å±€éƒ¨ç‰¹å¾**ï¼ˆ~100ç»´ï¼‰ï¼š
   - å¡è½¦ä½ç½®ã€é€Ÿåº¦ã€å®¹é‡ã€å½“å‰è´Ÿè½½
   - å¡è½¦åˆ°å„å¿«é€’æŸœçš„è·ç¦»
   - å¡è½¦åˆ°ä»“åº“çš„è·ç¦»

2. **å…¨å±€ç‰¹å¾**ï¼ˆ~200ç»´ï¼‰ï¼š
   - æ‰€æœ‰å¿«é€’æŸœçš„éœ€æ±‚çŠ¶æ€
   - æ‰€æœ‰å¿«é€’æŸœçš„æœåŠ¡çŠ¶æ€
   - å…¨å±€éœ€æ±‚åˆ†å¸ƒç»Ÿè®¡

3. **æ—¶ç©ºç‰¹å¾**ï¼ˆ~100ç»´ï¼‰ï¼š
   - å½“å‰æ—¶é—´æ­¥
   - å†å²è®¿é—®è®°å½•
   - æ—¶é—´çª—ä¿¡æ¯

4. **åŠ¨æ€ç‰¹å¾**ï¼ˆ~50ç»´ï¼‰ï¼š
   - éœ€æ±‚å˜åŒ–è¶‹åŠ¿
   - æœåŠ¡è¿›åº¦
   - åè°ƒä¿¡æ¯

**ä¸»è¦æ–¹æ³•**ï¼š
- `extract_features(env, truck_id)`: æå–å•ä¸ªå¡è½¦çš„çŠ¶æ€ç‰¹å¾
- `get_global_features(env)`: æå–å…¨å±€ç‰¹å¾
- `get_temporal_features(env, truck_id)`: æå–æ—¶ç©ºç‰¹å¾
- `get_dynamic_features(env)`: æå–åŠ¨æ€ç‰¹å¾

##### `TimeWindowConstraints`
**åŠŸèƒ½**ï¼šæ—¶é—´çª—çº¦æŸå¤„ç†ç±»

**ä¸»è¦æ–¹æ³•**ï¼š
- `check_violation(locker_id, current_time)`: æ£€æŸ¥æ—¶é—´çª—è¿è§„
- `calculate_penalty(locker_id, current_time)`: è®¡ç®—æ—¶é—´çª—æƒ©ç½š

---

### 5. `action_mask.py` - åŠ¨ä½œæ©ç ç®¡ç†

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/action_mask.py`  
**è¡Œæ•°**ï¼š968è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šè¿‡æ»¤æ— æ•ˆåŠ¨ä½œï¼Œæé«˜è®­ç»ƒæ•ˆç‡

#### 5.1 ä¸»è¦ç±»

##### `ActionMaskManager`
**åŠŸèƒ½**ï¼šåŠ¨ä½œæ©ç ç®¡ç†å™¨

**ä¸»è¦æ–¹æ³•**ï¼š
- `get_action_masks(env, truck_id)`: è·å–åŠ¨ä½œæ©ç 
  - `stop_mask`: åœé ç‚¹æ©ç ï¼ˆæ ‡è®°å¯è¾¾çš„åœé ç‚¹ï¼‰
  - `service_mask`: æœåŠ¡åŒºåŸŸæ©ç ï¼ˆæ ‡è®°å¯æœåŠ¡çš„å¿«é€’æŸœï¼‰
  
- `_compute_stop_mask(...)`: è®¡ç®—åœé ç‚¹æ©ç 
  - è€ƒè™‘å½“å‰ä½ç½®
  - è€ƒè™‘è·ç¦»çº¦æŸ
  - è€ƒè™‘å·²è®¿é—®çŠ¶æ€

- `_compute_service_mask(...)`: è®¡ç®—æœåŠ¡åŒºåŸŸæ©ç 
  - è€ƒè™‘èˆªç¨‹é™åˆ¶
  - è€ƒè™‘å®¹é‡çº¦æŸ
  - è€ƒè™‘éœ€æ±‚çŠ¶æ€

---

### 6. `dynamic_drone_scheduler.py` - åŠ¨æ€æ— äººæœºè°ƒåº¦

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/dynamic_drone_scheduler.py`  
**è¡Œæ•°**ï¼š938è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šåœ¨300ç§’æ—¶é—´çª—å†…ä¼˜åŒ–æ— äººæœºä»»åŠ¡åˆ†é…

#### 6.1 ä¸»è¦ç±»

##### `DroneTask`
**åŠŸèƒ½**ï¼šæ— äººæœºä»»åŠ¡æ•°æ®ç»“æ„

**å±æ€§**ï¼š
- `locker_id`: ç›®æ ‡å¿«é€’æŸœID
- `locker_position`: å¿«é€’æŸœä½ç½®
- `delivery_demand`: å–è´§éœ€æ±‚
- `return_demand`: é€€è´§éœ€æ±‚
- `distance`: é£è¡Œè·ç¦»
- `flight_time`: é£è¡Œæ—¶é—´
- `service_time`: æœåŠ¡æ—¶é—´
- `total_time`: æ€»æ—¶é—´

##### `DroneSchedule`
**åŠŸèƒ½**ï¼šæ— äººæœºè°ƒåº¦æ–¹æ¡ˆ

**å±æ€§**ï¼š
- `tasks`: ä»»åŠ¡åˆ—è¡¨
- `total_time`: æ€»æ—¶é—´
- `total_distance`: æ€»è·ç¦»
- `penalty`: è¶…æ—¶æƒ©ç½š

##### `DynamicDroneScheduler`
**åŠŸèƒ½**ï¼šåŠ¨æ€è§„åˆ’æ— äººæœºè°ƒåº¦å™¨

**åˆå§‹åŒ–å‚æ•°**ï¼š
- `max_service_time`: æœ€å¤§æœåŠ¡æ—¶é—´ï¼ˆ300ç§’ï¼‰
- `drone_speed`: æ— äººæœºé€Ÿåº¦ï¼ˆ1.0ï¼‰
- `service_time_per_item`: æ¯é¡¹éœ€æ±‚æœåŠ¡æ—¶é—´ï¼ˆ2ç§’ï¼‰

**ä¸»è¦æ–¹æ³•**ï¼š
- `schedule_drones(truck_location, available_lockers, drone_range)`: è°ƒåº¦æ— äººæœº
  - åˆ›å»ºæœ‰æ•ˆä»»åŠ¡åˆ—è¡¨
  - ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–ä»»åŠ¡åˆ†é…
  - è€ƒè™‘æ—¶é—´çª—çº¦æŸå’Œè¶…æ—¶æƒ©ç½š
  
- `_create_valid_tasks(...)`: åˆ›å»ºæœ‰æ•ˆä»»åŠ¡åˆ—è¡¨
  - æ£€æŸ¥èˆªç¨‹é™åˆ¶ï¼š$2 \times distance \leq drone\_range$
  - è®¡ç®—é¢„ä¼°å®Œæˆæ—¶é—´

- `_optimize_schedule(...)`: ä½¿ç”¨DPä¼˜åŒ–è°ƒåº¦
  - çŠ¶æ€ï¼šæ—¶é—´ã€å·²åˆ†é…ä»»åŠ¡
  - è½¬ç§»ï¼šåˆ†é…æ–°ä»»åŠ¡
  - ç›®æ ‡ï¼šæœ€å¤§åŒ–æœåŠ¡éœ€æ±‚ï¼Œæœ€å°åŒ–è¶…æ—¶æƒ©ç½š

---

### 7. `dynamic_step_implementation.py` - åŠ¨æ€æ­¥éª¤å®ç°

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/dynamic_step_implementation.py`  
**è¡Œæ•°**ï¼š286è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šå®ç°åŠ¨æ€è°ƒåº¦é€»è¾‘çš„æ ¸å¿ƒæ­¥éª¤

#### 7.1 ä¸»è¦å‡½æ•°

##### `get_serviceable_lockers(truck_position, lockers_state, max_range)`
**åŠŸèƒ½**ï¼šè·å–å¯æœåŠ¡çš„å¿«é€’æŸœåˆ—è¡¨

**å‚æ•°**ï¼š
- `truck_position`: å¡è½¦ä½ç½®
- `lockers_state`: å¿«é€’æŸœçŠ¶æ€åˆ—è¡¨
- `max_range`: æœ€å¤§æœåŠ¡èŒƒå›´ï¼ˆé»˜è®¤100.0ï¼‰

**è¿”å›**ï¼šå¯æœåŠ¡çš„å¿«é€’æŸœåˆ—è¡¨ï¼ˆåœ¨èˆªç¨‹èŒƒå›´å†…ä¸”æœªæœåŠ¡ï¼‰

##### `execute_drone_schedule(env, truck, schedule_result, truck_id)`
**åŠŸèƒ½**ï¼šæ‰§è¡Œæ— äººæœºè°ƒåº¦æ–¹æ¡ˆ

**æµç¨‹**ï¼š
1. æ›´æ–°å¿«é€’æŸœéœ€æ±‚ï¼ˆå®Œæˆé…é€å’Œé€€è´§ï¼‰
2. æ›´æ–°å¡è½¦è´Ÿè½½
3. è®¡ç®—æœåŠ¡å¥–åŠ±
4. è¿”å›å¥–åŠ±å’Œæ—¶é—´æˆæœ¬

##### `calculate_step_reward(schedule_result, time_penalty)`
**åŠŸèƒ½**ï¼šè®¡ç®—æ­¥éª¤å¥–åŠ±

**ç»„æˆ**ï¼š
- æœåŠ¡å®Œæˆå¥–åŠ±
- æ—¶é—´æƒ©ç½šï¼ˆè¶…æ—¶æƒ©ç½šï¼‰

##### `dynamic_step(env, actions)`
**åŠŸèƒ½**ï¼šæ ¸å¿ƒåŠ¨æ€æ­¥éª¤é€»è¾‘

**æµç¨‹**ï¼š
1. è§£æåŠ¨ä½œï¼ˆåœé ç‚¹é€‰æ‹©ã€æœåŠ¡åŒºåŸŸé€‰æ‹©ï¼‰
2. ç§»åŠ¨å¡è½¦åˆ°åœé ç‚¹
3. è·å–å¯æœåŠ¡å¿«é€’æŸœ
4. è°ƒç”¨æ— äººæœºè°ƒåº¦å™¨ç”Ÿæˆè°ƒåº¦æ–¹æ¡ˆ
5. æ‰§è¡Œè°ƒåº¦æ–¹æ¡ˆ
6. è®¡ç®—å¥–åŠ±
7. æ£€æŸ¥æ˜¯å¦ç»“æŸ
8. è¿”å›(next_state, rewards, done, info)

---

### 8. `soft_time_window.py` - è½¯æ—¶é—´çª—ç®¡ç†

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/soft_time_window.py`  
**ä¸»è¦åŠŸèƒ½**ï¼šå¤„ç†è½¯æ—¶é—´çª—çº¦æŸ

#### 8.1 ä¸»è¦ç±»

##### `SoftTimeWindowManager`
**åŠŸèƒ½**ï¼šè½¯æ—¶é—´çª—ç®¡ç†å™¨

**æƒ©ç½šå‡½æ•°ç±»å‹**ï¼š
- `LINEAR`: çº¿æ€§æƒ©ç½š
- `QUADRATIC`: äºŒæ¬¡æƒ©ç½šï¼ˆé»˜è®¤ï¼‰
- `EXPONENTIAL`: æŒ‡æ•°æƒ©ç½š

**ä¸»è¦æ–¹æ³•**ï¼š
- `calculate_penalty(locker_id, arrival_time)`: è®¡ç®—æ—¶é—´çª—æƒ©ç½š
  - æ—©åˆ°æƒ©ç½šï¼š$\alpha \times (t_{start} - t)^2$
  - è¶…æ—¶æƒ©ç½šï¼š$\beta \times (t - t_{end})^2$

##### `TimeWindowOptimizer`
**åŠŸèƒ½**ï¼šæ—¶é—´çª—ä¼˜åŒ–å™¨ï¼Œä¼˜åŒ–æœåŠ¡æ—¶é—´å®‰æ’

---

### 9. `truck_replenishment.py` - è¡¥è´§ä¼˜åŒ–

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/truck_replenishment.py`  
**è¡Œæ•°**ï¼š446è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šæ™ºèƒ½å†³ç­–å¡è½¦ä½•æ—¶è¿”å›ä»“åº“è¡¥è´§

#### 9.1 ä¸»è¦ç±»

##### `ReplenishmentOptimizer`
**åŠŸèƒ½**ï¼šè¡¥è´§ä¼˜åŒ–å™¨

**è¡¥è´§ç­–ç•¥**ï¼š
- `FIXED_THRESHOLD`: å›ºå®šé˜ˆå€¼ç­–ç•¥
- `ADAPTIVE`: è‡ªé€‚åº”ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰
- `DEMAND_BASED`: åŸºäºéœ€æ±‚çš„ç­–ç•¥

**ä¸»è¦æ–¹æ³•**ï¼š
- `should_replenish(truck_state, locker_demands, depot_distance)`: åˆ¤æ–­æ˜¯å¦åº”è¯¥è¡¥è´§
  - è€ƒè™‘å®¹é‡åˆ©ç”¨ç‡
  - è€ƒè™‘å‰©ä½™éœ€æ±‚
  - è€ƒè™‘åˆ°ä»“åº“çš„è·ç¦»

---

### 10. `demand_model.py` - éœ€æ±‚å»ºæ¨¡

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/demand_model.py`  
**ä¸»è¦åŠŸèƒ½**ï¼šéœ€æ±‚å»ºæ¨¡å’Œé¢„æµ‹

#### 10.1 ä¸»è¦ç±»

##### `UncertaintyHandler`
**åŠŸèƒ½**ï¼šä¸ç¡®å®šæ€§å¤„ç†å™¨ï¼Œå¤„ç†éœ€æ±‚ä¸ç¡®å®šæ€§

**ä¸»è¦æ–¹æ³•**ï¼š
- `generate_demand(locker_id)`: ç”Ÿæˆéœ€æ±‚ï¼ˆæ³Šæ¾åˆ†å¸ƒï¼‰
- `update_demand_history(...)`: æ›´æ–°éœ€æ±‚å†å²
- `predict_demand(...)`: é¢„æµ‹éœ€æ±‚

---

### 11. `config.py` - é…ç½®æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**ï¼š`/home/gzw/bad_truck_drone/config.py`  
**è¡Œæ•°**ï¼š228è¡Œ  
**ä¸»è¦åŠŸèƒ½**ï¼šç³»ç»Ÿå…¨å±€é…ç½®ç®¡ç†

#### 11.1 æ¨¡å—çº§åˆ«å‚æ•°

**ç¯å¢ƒå‚æ•°**ï¼š
- `DEPOT = (0, 0)`: ä»“åº“ä½ç½®
- `CENTER = (0, 0)`: ä¸­å¿ƒç‚¹åæ ‡
- `DRONE_MAX_RANGE = 50`: æ— äººæœºæœ€å¤§èˆªç¨‹
- `TRUCK_CAPACITY = 100`: å¡è½¦å®¹é‡
- `MAX_TIMESTEPS = 600`: æœ€å¤§æ—¶é—´æ­¥æ•°

**è®­ç»ƒå‚æ•°**ï¼š
- `TOTAL_TIMESTEPS = 50000`: æ€»è®­ç»ƒæ­¥æ•°
- `LEARNING_RATE = 3e-4`: å­¦ä¹ ç‡
- `BATCH_SIZE = 256`: æ‰¹æ¬¡å¤§å°
- `GAMMA = 0.99`: æŠ˜æ‰£å› å­
- `GAE_LAMBDA = 0.95`: GAEå‚æ•°

**æ•°æ®é›†ç”Ÿæˆå‚æ•°**ï¼š
- `DATASET_SIZE = 1000`: æ•°æ®é›†å¤§å°
- `MIN_LOCKERS = 2`: æœ€å°å¿«é€’æŸœæ•°é‡
- `MAX_LOCKERS = 10`: æœ€å¤§å¿«é€’æŸœæ•°é‡
- `DEMAND_MIN = 1`: æœ€å°éœ€æ±‚
- `DEMAND_MAX = 10`: æœ€å¤§éœ€æ±‚

#### 11.2 Configç±»

**å¥–åŠ±å‡½æ•°æƒé‡**ï¼š
- `truck_routing_cost = 0.035`
- `drone_routing_cost = 0.002`
- `serve_reward = 1.0`
- `unserved_punishment = 10.0`

**ç¯å¢ƒå‚æ•°**ï¼š
- `num_lockers = 50`: å¿«é€’æŸœæ•°é‡
- `boundary = 100`: åœ°å›¾è¾¹ç•Œ
- `DRONE_NUM = 3`: æ¯è¾†å¡è½¦çš„æ— äººæœºæ•°é‡
- `DRONE_SPEED = 1.0`: æ— äººæœºé€Ÿåº¦
- `TRUCK_SPEED = 20`: å¡è½¦é€Ÿåº¦

**è®­ç»ƒè¶…å‚æ•°**ï¼š
- `TOTAL_TIMESTEPS = 100000`
- `LEARNING_RATE = 1e-4`
- `BATCH_SIZE = 512`
- `CLIP_RANGE = 0.05`
- `ENT_COEF = 0.02`
- `VF_COEF = 0.5`
- `MAX_GRAD_NORM = 0.3`

---

## ğŸ”„ æ–‡ä»¶ä¾èµ–å…³ç³»

```
start_training.py
    â”œâ”€â”€ truck_routing.py
    â”‚   â”œâ”€â”€ reward_function.py
    â”‚   â”œâ”€â”€ state_representation.py
    â”‚   â”œâ”€â”€ action_mask.py
    â”‚   â”œâ”€â”€ demand_model.py
    â”‚   â”œâ”€â”€ soft_time_window.py
    â”‚   â”œâ”€â”€ truck_replenishment.py
    â”‚   â”œâ”€â”€ dynamic_drone_scheduler.py
    â”‚   â”œâ”€â”€ dynamic_step_implementation.py
    â”‚   â””â”€â”€ generate_model_dataset.py (ç‰¹å¾è®¡ç®—å‡½æ•°)
    â””â”€â”€ config.py
```

---

## ğŸ“Š è®­ç»ƒæµç¨‹

### å®Œæ•´è®­ç»ƒæµç¨‹

1. **åˆå§‹åŒ–é˜¶æ®µ**ï¼ˆ`start_training.py` â†’ `run_training_session()`ï¼‰
   - åˆ›å»ºç¯å¢ƒï¼ˆ`TruckSchedulingEnv`ï¼‰
   - åˆ›å»ºè®­ç»ƒç®¡ç†å™¨ï¼ˆ`TrainingManager`ï¼‰
   - åˆå§‹åŒ–ä¼˜åŒ–ç»„ä»¶ï¼ˆå­¦ä¹ ç‡è°ƒåº¦å™¨ã€æ¢ç´¢è°ƒåº¦å™¨ç­‰ï¼‰

2. **è®­ç»ƒå¾ªç¯**ï¼ˆ`truck_routing.py` â†’ `train_marl()`ï¼‰
   - æ”¶é›†ç»éªŒï¼ˆrolloutï¼‰ï¼š
     - ç¯å¢ƒé‡ç½®ï¼ˆ`env.reset()`ï¼‰
     - æ‰§è¡ŒåŠ¨ä½œï¼ˆ`mappo.act()`ï¼‰
     - ç¯å¢ƒæ­¥è¿›ï¼ˆ`env.step()`ï¼‰
     - è®¡ç®—å¥–åŠ±ï¼ˆ`reward_function.calculate_reward()`ï¼‰
   - æ›´æ–°ç½‘ç»œï¼š
     - è®¡ç®—GAEä¼˜åŠ¿
     - PPOæ›´æ–°ï¼ˆå¤šè½®ï¼‰
     - æ¢¯åº¦è£å‰ª
   - è®°å½•è¿›åº¦ï¼ˆ`training_manager.log_training_progress()`ï¼‰

3. **åŠ¨æ€è°ƒåº¦**ï¼ˆ`dynamic_step_implementation.py` â†’ `dynamic_step()`ï¼‰
   - è§£æåŠ¨ä½œ
   - ç§»åŠ¨å¡è½¦
   - è·å–å¯æœåŠ¡å¿«é€’æŸœï¼ˆ`get_serviceable_lockers()`ï¼‰
   - è°ƒåº¦æ— äººæœºï¼ˆ`DynamicDroneScheduler.schedule_drones()`ï¼‰
   - æ‰§è¡Œè°ƒåº¦ï¼ˆ`execute_drone_schedule()`ï¼‰

4. **çŠ¶æ€è¡¨ç¤º**ï¼ˆ`state_representation.py` â†’ `StateRepresentation.extract_features()`ï¼‰
   - æå–å±€éƒ¨ç‰¹å¾
   - æå–å…¨å±€ç‰¹å¾
   - æå–æ—¶ç©ºç‰¹å¾
   - æå–åŠ¨æ€ç‰¹å¾

5. **åŠ¨ä½œé€‰æ‹©**ï¼ˆ`truck_routing.py` â†’ `MAPPO.act()`ï¼‰
   - è·å–åŠ¨ä½œæ©ç ï¼ˆ`ActionMaskManager.get_action_masks()`ï¼‰
   - ç­–ç•¥ç½‘ç»œå‰å‘ä¼ æ’­
   - é‡‡æ ·åŠ¨ä½œï¼ˆè€ƒè™‘æ©ç ï¼‰

6. **å¥–åŠ±è®¡ç®—**ï¼ˆ`reward_function.py` â†’ `RewardFunction.calculate_reward()`ï¼‰
   - æœåŠ¡å®Œæˆå¥–åŠ±
   - è¿è¥æ•ˆç‡å¥–åŠ±
   - æˆæœ¬æ§åˆ¶æƒ©ç½š
   - çº¦æŸè¿è§„æƒ©ç½š
   - ç­–ç•¥ä¼˜åŒ–å¥–åŠ±

7. **è®­ç»ƒä¼˜åŒ–**ï¼ˆ`start_training.py` â†’ `TrainingManager`ï¼‰
   - å¥–åŠ±å¹³æ»‘
   - å­¦ä¹ ç‡è°ƒæ•´
   - æ¢ç´¢ç­–ç•¥è°ƒæ•´
   - æ”¶æ•›æ£€æµ‹

8. **ç»“æœä¿å­˜**ï¼ˆ`start_training.py` â†’ `TrainingManager`ï¼‰
   - ä¿å­˜æ¨¡å‹
   - ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
   - ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

---

## ğŸ¯ å…³é”®ç®—æ³•å®ç°

### MAPPOç®—æ³•æµç¨‹

1. **ç»éªŒæ”¶é›†**ï¼š
   ```python
   for step in range(rollout_length):
       actions, log_probs, values = mappo.act(states, action_masks, env)
       next_states, rewards, dones, info = env.step(actions)
       # å­˜å‚¨ç»éªŒ
   ```

2. **GAEè®¡ç®—**ï¼š
   ```python
   advantages = compute_gae(rewards, values, dones, gamma, gae_lambda)
   returns = advantages + values
   ```

3. **PPOæ›´æ–°**ï¼š
   ```python
   for epoch in range(n_epochs):
       # è®¡ç®—æ–°ç­–ç•¥çš„logæ¦‚ç‡
       new_log_probs = policy_net(states, actions)
       # è®¡ç®—æ¯”ç‡
       ratio = exp(new_log_probs - old_log_probs)
       # PPOè£å‰ª
       clipped_ratio = clip(ratio, 1-epsilon, 1+epsilon)
       # ç­–ç•¥æŸå¤±
       policy_loss = -min(ratio * advantages, clipped_ratio * advantages)
       # ä»·å€¼æŸå¤±
       value_loss = (values - returns)^2
       # ç†µå¥–åŠ±
       entropy = -sum(p * log(p))
       # æ€»æŸå¤±
       loss = policy_loss + value_coef * value_loss - entropy_coef * entropy
   ```

### åŠ¨æ€æ— äººæœºè°ƒåº¦ç®—æ³•

1. **ä»»åŠ¡åˆ›å»º**ï¼š
   - éå†æ‰€æœ‰å¿«é€’æŸœ
   - æ£€æŸ¥èˆªç¨‹é™åˆ¶
   - è®¡ç®—é£è¡Œæ—¶é—´å’ŒæœåŠ¡æ—¶é—´
   - åˆ›å»ºæœ‰æ•ˆä»»åŠ¡åˆ—è¡¨

2. **åŠ¨æ€è§„åˆ’ä¼˜åŒ–**ï¼š
   - çŠ¶æ€ï¼šå½“å‰æ—¶é—´ã€å·²åˆ†é…ä»»åŠ¡
   - è½¬ç§»ï¼šåˆ†é…æ–°ä»»åŠ¡
   - ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–æœåŠ¡éœ€æ±‚ - è¶…æ—¶æƒ©ç½š
   - ä½¿ç”¨DPæ±‚è§£æœ€ä¼˜è°ƒåº¦æ–¹æ¡ˆ

---

## ğŸ“ é…ç½®å‚æ•°è¯´æ˜

### è®­ç»ƒç›¸å…³å‚æ•°ï¼ˆconfig.pyï¼‰

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `TOTAL_TIMESTEPS` | 50000 | æ€»è®­ç»ƒæ­¥æ•° |
| `LEARNING_RATE` | 3e-4 | åˆå§‹å­¦ä¹ ç‡ |
| `BATCH_SIZE` | 256 | æ‰¹æ¬¡å¤§å° |
| `GAMMA` | 0.99 | æŠ˜æ‰£å› å­ |
| `GAE_LAMBDA` | 0.95 | GAEå‚æ•° |
| `CLIP_RANGE` | 0.05 | PPOè£å‰ªèŒƒå›´ |
| `ENT_COEF` | 0.02 | ç†µç³»æ•° |
| `VF_COEF` | 0.5 | ä»·å€¼å‡½æ•°æƒé‡ |
| `MAX_GRAD_NORM` | 0.3 | æœ€å¤§æ¢¯åº¦èŒƒæ•° |

### ç¯å¢ƒç›¸å…³å‚æ•°ï¼ˆconfig.pyï¼‰

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `num_lockers` | 50 | å¿«é€’æŸœæ•°é‡ |
| `boundary` | 100 | åœ°å›¾è¾¹ç•ŒèŒƒå›´ |
| `TRUCK_CAPACITY` | 100 | å¡è½¦å®¹é‡ |
| `DRONE_MAX_RANGE` | 50 | æ— äººæœºæœ€å¤§èˆªç¨‹ |
| `DRONE_NUM` | 3 | æ¯è¾†å¡è½¦çš„æ— äººæœºæ•°é‡ |
| `MAX_TIMESTEPS` | 600 | æœ€å¤§æ—¶é—´æ­¥æ•° |

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬è®­ç»ƒ

```python
from start_training import run_training_session

# è¿è¡Œè®­ç»ƒ
result = run_training_session(
    num_episodes=15000,
    enable_optimization=True
)

if result['status'] == 'success':
    print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {result['model_path']}")
    print(f"æœ€ç»ˆæ€§èƒ½: {result['performance']['best_reward']}")
```

### è‡ªå®šä¹‰é…ç½®è®­ç»ƒ

```python
import config

# ä¿®æ”¹é…ç½®
config.Config.num_lockers = 30
config.Config.DRONE_MAX_RANGE = 40
config.LEARNING_RATE = 1e-4

# è¿è¡Œè®­ç»ƒ
result = run_training_session(num_episodes=10000)
```

---

## ğŸ“ˆ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆï¼š

1. **æ¨¡å‹æ–‡ä»¶**ï¼š
   - `trained_mappo_policy.pth`: è®­ç»ƒå¥½çš„æ¨¡å‹

2. **è®­ç»ƒæŠ¥å‘Š**ï¼š
   - `training_report.json`: å®Œæ•´è®­ç»ƒæŠ¥å‘Šï¼ˆJSONæ ¼å¼ï¼‰
   - `training_analysis.png`: è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å›¾è¡¨
   - `loss_analysis.png`: æŸå¤±å‡½æ•°åˆ†æå›¾è¡¨

3. **è®­ç»ƒæ—¥å¿—**ï¼š
   - æ§åˆ¶å°è¾“å‡ºï¼šå®æ—¶è®­ç»ƒè¿›åº¦
   - è®­ç»ƒæŠ¥å‘Šï¼šåŒ…å«æ‰€æœ‰è®­ç»ƒæŒ‡æ ‡å’Œå†å²æ•°æ®

---

## ğŸ“ æŠ€æœ¯è¦ç‚¹æ€»ç»“

1. **å¤šæ™ºèƒ½ä½“ååŒ**ï¼šæ¯è¾†å¡è½¦ç‹¬ç«‹å†³ç­–ï¼Œé€šè¿‡å…±äº«ç»éªŒååŒä¼˜åŒ–
2. **åŠ¨æ€è°ƒåº¦**ï¼š300ç§’æ—¶é—´çª—å†…ä½¿ç”¨DPä¼˜åŒ–æ— äººæœºä»»åŠ¡åˆ†é…
3. **çŠ¶æ€è¡¨ç¤º**ï¼šå¤šå±‚æ¬¡ç‰¹å¾æå–ï¼ˆå±€éƒ¨+å…¨å±€+æ—¶ç©º+åŠ¨æ€ï¼‰
4. **åŠ¨ä½œæ©ç **ï¼šå¤§å¹…å‡å°‘æ— æ•ˆåŠ¨ä½œï¼Œæé«˜è®­ç»ƒæ•ˆç‡
5. **è‡ªé€‚åº”ä¼˜åŒ–**ï¼šå­¦ä¹ ç‡ã€æ¢ç´¢ç­–ç•¥ã€å¥–åŠ±æƒé‡åŠ¨æ€è°ƒæ•´
6. **è½¯çº¦æŸå¤„ç†**ï¼šæ—¶é—´çª—ã€å®¹é‡ç­‰çº¦æŸé€šè¿‡æƒ©ç½šè€Œéç¡¬é™åˆ¶

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2025-11-20  
**ä½œè€…**ï¼šDionysus

